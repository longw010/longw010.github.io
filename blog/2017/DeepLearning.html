<!DOCTYPE HTML>
<html>
<head>
  <title>Long</title>
	<meta name="google-site-verification" content="_icP2W3B6y_gFG92Dh-caUWIh_sEnE4tPu8pghzaH2w" />
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <link href="https://fonts.googleapis.com/css?family=Julius+Sans+One" rel="stylesheet">
  <link rel="stylesheet" href="../../css/style.css">
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script>
	$(document).ready(function(){
	  $("a").on('click', function(event) {
	    if (this.hash !== "") {
	      event.preventDefault();
	
	      var hash = this.hash;
	
	      $('html, body').animate({
	        scrollTop: $(hash).offset().top
	      }, 500, function(){
	        window.location.hash = hash;
	      });
	    }
	  });
	});
	</script>
</head>

<body>
  <div class="banner">
    <div id="header">
      <div id="name">
        Long Wang <a href="#about"> <img src="images/name.png" width="56" height="28" border="0"></a>
      </div>
      <div id="navigator">
        <div class="nav_cell"><a class="nav" href="../../index.html">ABOUT</a></div>
        <div class="nav_cell"><a class="nav" href="../../blog.html">BLOG</a></div>
      </div>
    </div>
  </div>

  <hr>

  <div id="main">
  <div class='date'>
      Nov 20, 2017 </div>
    <div class="title"> Building NN, RBM, autoencoder, and RNN from scratch </div>
    <p> In this blog, we discussed how to build some simple neural networks from scratch. The full code can be found <a href="https://github.com/longw010/DL_Notes"> here</a>. </p>

    <div class="subtitle"> NN </div>
    Implement the backpropagation algorithm with sigmoid activation function in a single-layer neural network. The output layer should be a softmax output over 10 classes corresponding to 10 classes of handwritten digits. 
    <p> Detailed implementation is <a href="https://github.com/longw010/DL_Notes/blob/master/rnn/train.py"> here </a> . </p>
    
    <div class='subtitle'> Unsupervised learning : RBM, autoencoder </div>
    <p>Train an RBM model with 100 hidden units, starting with CD with k = 1 step. For initialization use samples from a normal distribution with mean 0 and standard deviation 0.1. </p>
    <p> Detailed implementation is <a href="https://github.com/longw010/DL_Notes/blob/master/rnn/train.py"> here </a> . </p>

    <div class='subtitle'> RNN </div>
    <p> A 4-gram language model using a Multilayer Perceptron with an embedding layer is built according to Figure 1. For each of the 4 word combinations, the next word is predicted given the first three words.  
    <embed src="/blog/2017/DeepLearning/rnn.png"> </p>
    <div class='subsubtitle'> Preprossessing: </div>
    We first sorted the tokens by frequency, and only saved the top 8000 tokens; then we added "START" and "END" tags to the start and end of sentences. For the tokens that are not in the 8000 word of bags above, they are replaced by "UNK".
    <p> Detailed implementation is <a href="https://github.com/longw010/DL_Notes/blob/master/rnn/train.py"> here </a> . </p>

	</div>


  <div style="margin-top: 10px; text-align: center; font-size: 14px;">
  Copyright &copy; 2016 - 2017, Long Wang. All rights reserved.<br>
  Last Updated: Dec 7, 2017
  </div>

	<!-- Start of StatCounter Code for Default Guide -->
	<script type="text/javascript">
		var sc_project=10595714; 
		var sc_invisible=1; 
		var sc_security="ee39bc4f"; 
		var scJsHost = (("https:" == document.location.protocol) ?
			"https://secure." : "http://www.");
		document.write("<sc"+"ript type='text/javascript' src='" +
			scJsHost+
			"statcounter.com/counter/counter.js'></"+"script>");
	</script>
	<noscript><div class="statcounter"><a title="shopify visitor
		statistics" href="http://statcounter.com/shopify/"
		target="_blank"><img class="statcounter"
		src="http://c.statcounter.com/10595714/0/ee39bc4f/1/"
		alt="shopify visitor statistics"></a></div></noscript>
		<!-- End of StatCounter Code for Default Guide -->

</body>
</html>
